{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, plot_roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../assets/processed_train.csv')\n",
    "df_prediction = pd.read_csv('../assets/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns='Unnamed: 0', inplace = True, axis = 1)\n",
    "df_prediction.drop(columns='Unnamed: 0', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16950 entries, 0 to 16949\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Date             16950 non-null  object \n",
      " 1   Species          16950 non-null  object \n",
      " 2   Trap             16950 non-null  object \n",
      " 3   Latitude         16950 non-null  float64\n",
      " 4   Longitude        16950 non-null  float64\n",
      " 5   NumMosquitos     16950 non-null  int64  \n",
      " 6   WnvPresent       16950 non-null  int64  \n",
      " 7   Nearest_Station  16950 non-null  int64  \n",
      " 8   Station          16950 non-null  int64  \n",
      " 9   Tavg             16950 non-null  float64\n",
      " 10  DewPoint         16950 non-null  int64  \n",
      " 11  WetBulb          16950 non-null  float64\n",
      " 12  PrecipTotal      16950 non-null  float64\n",
      " 13  StnPressure      16950 non-null  float64\n",
      " 14  AvgSpeed         16950 non-null  float64\n",
      " 15  Year             16950 non-null  float64\n",
      " 16  Month            16950 non-null  float64\n",
      " 17  WeekofYear       16950 non-null  float64\n",
      "dtypes: float64(10), int64(5), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232586 entries, 0 to 232585\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Id           232586 non-null  int64  \n",
      " 1   Date         232586 non-null  object \n",
      " 2   Species      232586 non-null  object \n",
      " 3   Trap         232586 non-null  object \n",
      " 4   Latitude     232586 non-null  float64\n",
      " 5   Longitude    232586 non-null  float64\n",
      " 6   Station      232586 non-null  int64  \n",
      " 7   Tavg         232586 non-null  float64\n",
      " 8   DewPoint     232586 non-null  int64  \n",
      " 9   WetBulb      232586 non-null  float64\n",
      " 10  PrecipTotal  232586 non-null  float64\n",
      " 11  StnPressure  232586 non-null  float64\n",
      " 12  AvgSpeed     232586 non-null  float64\n",
      " 13  Year         232586 non-null  float64\n",
      " 14  Month        232586 non-null  float64\n",
      " 15  WeekofYear   232586 non-null  float64\n",
      "dtypes: float64(10), int64(3), object(3)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prediction.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during the EDA portion the date has already been sprase out into 3 new columns 'Year', 'Month' & 'WeekofYear'\n",
    "# Since the test set does not have NumMosquitos this is also drop on the train set\n",
    "# Nearest_Station is also dropped as it was only use for EDA purpose\n",
    "df_train.drop(columns=['Date', 'NumMosquitos', 'Nearest_Station'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date is also drop from the prediction set, there is and Id column which is drop since it is only used for kaggle score\n",
    "df_prediction.drop(columns=['Date', 'Id'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16950, 15) (232586, 14)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_prediction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction['Species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Trap'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction['Trap'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns `Species` and `Trap` requires us to do do one-hot encoding however exploring the dataset, we can see that there is additional categorical information in `Species` and `Trap`, train set has `7 Species` category while prediction set has `8 Species` category. The same can be seen on `Trap` where train set has `136` vs `149` on the prediction set.  \n",
    "\n",
    "Using a combined dataset I created the dummy variables and then split them back into the appropriate dataframes again `train` and `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_num = len(df_train)\n",
    "\n",
    "# concat without the WnvPresent columns as that will be our target variable\n",
    "df_combine = pd.concat(objs = [df_train.drop('WnvPresent', axis = 1), df_prediction], axis = 0)\n",
    "\n",
    "# get dummy variables\n",
    "df_combine = pd.get_dummies(df_combine)\n",
    "\n",
    "# extract the train set out\n",
    "df_train_final = df_combine[:df_train_num]\n",
    "\n",
    "# extract the prediction set out\n",
    "df_prediction_final = df_combine[df_train_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to ensure that the shape row and columns are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16950, 169)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232586, 169)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the WnvPresent column back into the train set so that we can do a split later\n",
    "df_wnv = pd.DataFrame(df_train['WnvPresent'])\n",
    "df_train_final = pd.concat(objs = [df_train_final, df_wnv], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16950, 170)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WnvPresent                        1.000000\n",
       "WeekofYear                        0.100561\n",
       "Month                             0.097948\n",
       "Species_CULEX PIPIENS             0.097868\n",
       "DewPoint                          0.094676\n",
       "Species_CULEX RESTUANS            0.094047\n",
       "WetBulb                           0.086304\n",
       "Trap_T900                         0.080944\n",
       "Tavg                              0.078215\n",
       "Longitude                         0.076732\n",
       "Year                              0.043038\n",
       "Species_CULEX TERRITANS           0.038609\n",
       "Trap_T003                         0.036012\n",
       "Trap_T086                         0.034420\n",
       "Trap_T225                         0.034122\n",
       "AvgSpeed                          0.033466\n",
       "Trap_T143                         0.031773\n",
       "Latitude                          0.030862\n",
       "Trap_T115                         0.029565\n",
       "Trap_T002                         0.028303\n",
       "Trap_T223                         0.027643\n",
       "Trap_T046                         0.026868\n",
       "Trap_T006                         0.026601\n",
       "Trap_T233                         0.025025\n",
       "Species_CULEX SALINARIUS          0.023743\n",
       "Trap_T013                         0.023042\n",
       "Trap_T235                         0.022932\n",
       "Trap_T017                         0.022860\n",
       "Trap_T014                         0.022670\n",
       "Trap_T230                         0.021912\n",
       "Trap_T148                         0.021312\n",
       "Trap_T200                         0.021250\n",
       "Trap_T018                         0.020661\n",
       "Trap_T043                         0.020328\n",
       "Species_CULEX PIPIENS/RESTUANS    0.019620\n",
       "Trap_T103                         0.019373\n",
       "Trap_T015                         0.019373\n",
       "Trap_T096                         0.019099\n",
       "Trap_T903                         0.018874\n",
       "Trap_T011                         0.018459\n",
       "Trap_T049                         0.018438\n",
       "Name: WnvPresent, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = df_train_final.corr()\n",
    "columns = abs(corrmat['WnvPresent']).sort_values(ascending=False).head(41)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train_final.drop(columns = 'WnvPresent'), df_train_final['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Station</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>AvgSpeed</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekofYear</th>\n",
       "      <th>Species_CULEX ERRATICUS</th>\n",
       "      <th>Species_CULEX PIPIENS</th>\n",
       "      <th>Species_CULEX PIPIENS/RESTUANS</th>\n",
       "      <th>Species_CULEX RESTUANS</th>\n",
       "      <th>Species_CULEX SALINARIUS</th>\n",
       "      <th>Species_CULEX TARSALIS</th>\n",
       "      <th>Species_CULEX TERRITANS</th>\n",
       "      <th>Species_UNSPECIFIED CULEX</th>\n",
       "      <th>Trap_T001</th>\n",
       "      <th>Trap_T002</th>\n",
       "      <th>Trap_T002A</th>\n",
       "      <th>Trap_T002B</th>\n",
       "      <th>Trap_T003</th>\n",
       "      <th>Trap_T004</th>\n",
       "      <th>Trap_T005</th>\n",
       "      <th>Trap_T006</th>\n",
       "      <th>Trap_T007</th>\n",
       "      <th>Trap_T008</th>\n",
       "      <th>Trap_T009</th>\n",
       "      <th>Trap_T011</th>\n",
       "      <th>Trap_T012</th>\n",
       "      <th>Trap_T013</th>\n",
       "      <th>Trap_T014</th>\n",
       "      <th>Trap_T015</th>\n",
       "      <th>Trap_T016</th>\n",
       "      <th>Trap_T017</th>\n",
       "      <th>Trap_T018</th>\n",
       "      <th>Trap_T019</th>\n",
       "      <th>Trap_T025</th>\n",
       "      <th>Trap_T027</th>\n",
       "      <th>Trap_T028</th>\n",
       "      <th>Trap_T030</th>\n",
       "      <th>Trap_T031</th>\n",
       "      <th>Trap_T033</th>\n",
       "      <th>Trap_T034</th>\n",
       "      <th>Trap_T035</th>\n",
       "      <th>Trap_T036</th>\n",
       "      <th>Trap_T037</th>\n",
       "      <th>Trap_T039</th>\n",
       "      <th>Trap_T040</th>\n",
       "      <th>Trap_T043</th>\n",
       "      <th>Trap_T044</th>\n",
       "      <th>Trap_T045</th>\n",
       "      <th>Trap_T046</th>\n",
       "      <th>Trap_T047</th>\n",
       "      <th>Trap_T048</th>\n",
       "      <th>Trap_T049</th>\n",
       "      <th>Trap_T050</th>\n",
       "      <th>Trap_T051</th>\n",
       "      <th>Trap_T054</th>\n",
       "      <th>Trap_T054C</th>\n",
       "      <th>Trap_T060</th>\n",
       "      <th>Trap_T061</th>\n",
       "      <th>Trap_T062</th>\n",
       "      <th>Trap_T063</th>\n",
       "      <th>Trap_T065</th>\n",
       "      <th>Trap_T065A</th>\n",
       "      <th>Trap_T066</th>\n",
       "      <th>Trap_T067</th>\n",
       "      <th>Trap_T069</th>\n",
       "      <th>Trap_T070</th>\n",
       "      <th>Trap_T071</th>\n",
       "      <th>Trap_T072</th>\n",
       "      <th>Trap_T073</th>\n",
       "      <th>Trap_T074</th>\n",
       "      <th>Trap_T075</th>\n",
       "      <th>Trap_T076</th>\n",
       "      <th>Trap_T077</th>\n",
       "      <th>Trap_T078</th>\n",
       "      <th>Trap_T079</th>\n",
       "      <th>Trap_T080</th>\n",
       "      <th>Trap_T081</th>\n",
       "      <th>Trap_T082</th>\n",
       "      <th>Trap_T083</th>\n",
       "      <th>Trap_T084</th>\n",
       "      <th>Trap_T085</th>\n",
       "      <th>Trap_T086</th>\n",
       "      <th>Trap_T088</th>\n",
       "      <th>Trap_T089</th>\n",
       "      <th>Trap_T090</th>\n",
       "      <th>Trap_T090A</th>\n",
       "      <th>Trap_T090B</th>\n",
       "      <th>Trap_T090C</th>\n",
       "      <th>Trap_T091</th>\n",
       "      <th>Trap_T092</th>\n",
       "      <th>Trap_T094</th>\n",
       "      <th>Trap_T094B</th>\n",
       "      <th>Trap_T095</th>\n",
       "      <th>Trap_T096</th>\n",
       "      <th>Trap_T097</th>\n",
       "      <th>Trap_T099</th>\n",
       "      <th>Trap_T100</th>\n",
       "      <th>Trap_T102</th>\n",
       "      <th>Trap_T103</th>\n",
       "      <th>Trap_T107</th>\n",
       "      <th>Trap_T114</th>\n",
       "      <th>Trap_T115</th>\n",
       "      <th>Trap_T128</th>\n",
       "      <th>Trap_T128A</th>\n",
       "      <th>Trap_T129</th>\n",
       "      <th>Trap_T135</th>\n",
       "      <th>Trap_T138</th>\n",
       "      <th>Trap_T141</th>\n",
       "      <th>Trap_T142</th>\n",
       "      <th>Trap_T143</th>\n",
       "      <th>Trap_T144</th>\n",
       "      <th>Trap_T145</th>\n",
       "      <th>Trap_T146</th>\n",
       "      <th>Trap_T147</th>\n",
       "      <th>Trap_T148</th>\n",
       "      <th>Trap_T149</th>\n",
       "      <th>Trap_T150</th>\n",
       "      <th>Trap_T151</th>\n",
       "      <th>Trap_T152</th>\n",
       "      <th>Trap_T153</th>\n",
       "      <th>Trap_T154</th>\n",
       "      <th>Trap_T155</th>\n",
       "      <th>Trap_T156</th>\n",
       "      <th>Trap_T157</th>\n",
       "      <th>Trap_T158</th>\n",
       "      <th>Trap_T159</th>\n",
       "      <th>Trap_T160</th>\n",
       "      <th>Trap_T161</th>\n",
       "      <th>Trap_T162</th>\n",
       "      <th>Trap_T200</th>\n",
       "      <th>Trap_T200A</th>\n",
       "      <th>Trap_T200B</th>\n",
       "      <th>Trap_T206</th>\n",
       "      <th>Trap_T209</th>\n",
       "      <th>Trap_T212</th>\n",
       "      <th>Trap_T215</th>\n",
       "      <th>Trap_T218</th>\n",
       "      <th>Trap_T218A</th>\n",
       "      <th>Trap_T218B</th>\n",
       "      <th>Trap_T218C</th>\n",
       "      <th>Trap_T219</th>\n",
       "      <th>Trap_T220</th>\n",
       "      <th>Trap_T221</th>\n",
       "      <th>Trap_T222</th>\n",
       "      <th>Trap_T223</th>\n",
       "      <th>Trap_T224</th>\n",
       "      <th>Trap_T225</th>\n",
       "      <th>Trap_T226</th>\n",
       "      <th>Trap_T227</th>\n",
       "      <th>Trap_T228</th>\n",
       "      <th>Trap_T229</th>\n",
       "      <th>Trap_T230</th>\n",
       "      <th>Trap_T231</th>\n",
       "      <th>Trap_T232</th>\n",
       "      <th>Trap_T233</th>\n",
       "      <th>Trap_T234</th>\n",
       "      <th>Trap_T235</th>\n",
       "      <th>Trap_T236</th>\n",
       "      <th>Trap_T237</th>\n",
       "      <th>Trap_T238</th>\n",
       "      <th>Trap_T900</th>\n",
       "      <th>Trap_T903</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>41.738903</td>\n",
       "      <td>-87.695443</td>\n",
       "      <td>2</td>\n",
       "      <td>53.5</td>\n",
       "      <td>38</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.65</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>41.867108</td>\n",
       "      <td>-87.654224</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>29.18</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>41.986921</td>\n",
       "      <td>-87.689778</td>\n",
       "      <td>2</td>\n",
       "      <td>72.5</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>29.14</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>41.911824</td>\n",
       "      <td>-87.726737</td>\n",
       "      <td>1</td>\n",
       "      <td>75.5</td>\n",
       "      <td>67</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>29.17</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>41.754676</td>\n",
       "      <td>-87.612922</td>\n",
       "      <td>1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>49</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.24</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Latitude  Longitude  Station  Tavg  DewPoint  WetBulb  PrecipTotal  \\\n",
       "12459  41.738903 -87.695443        2  53.5        38     47.0         0.00   \n",
       "835    41.867108 -87.654224        2  77.0        69     71.0         0.92   \n",
       "7445   41.986921 -87.689778        2  72.5        60     65.0         0.19   \n",
       "2504   41.911824 -87.726737        1  75.5        67     70.0         0.23   \n",
       "6156   41.754676 -87.612922        1  61.5        49     55.0         0.00   \n",
       "\n",
       "       StnPressure  AvgSpeed    Year  Month  WeekofYear  \\\n",
       "12459        29.65       3.7  2011.0    9.0        37.0   \n",
       "835          29.18      10.6  2007.0    7.0        29.0   \n",
       "7445         29.14       9.6  2009.0    7.0        30.0   \n",
       "2504         29.17       5.8  2007.0    8.0        33.0   \n",
       "6156         29.24       5.8  2009.0    6.0        24.0   \n",
       "\n",
       "       Species_CULEX ERRATICUS  Species_CULEX PIPIENS  \\\n",
       "12459                        0                      0   \n",
       "835                          0                      0   \n",
       "7445                         0                      1   \n",
       "2504                         0                      0   \n",
       "6156                         0                      0   \n",
       "\n",
       "       Species_CULEX PIPIENS/RESTUANS  Species_CULEX RESTUANS  \\\n",
       "12459                               1                       0   \n",
       "835                                 1                       0   \n",
       "7445                                0                       0   \n",
       "2504                                0                       1   \n",
       "6156                                1                       0   \n",
       "\n",
       "       Species_CULEX SALINARIUS  Species_CULEX TARSALIS  \\\n",
       "12459                         0                       0   \n",
       "835                           0                       0   \n",
       "7445                          0                       0   \n",
       "2504                          0                       0   \n",
       "6156                          0                       0   \n",
       "\n",
       "       Species_CULEX TERRITANS  Species_UNSPECIFIED CULEX  Trap_T001  \\\n",
       "12459                        0                          0          0   \n",
       "835                          0                          0          0   \n",
       "7445                         0                          0          0   \n",
       "2504                         0                          0          0   \n",
       "6156                         0                          0          0   \n",
       "\n",
       "       Trap_T002  Trap_T002A  Trap_T002B  Trap_T003  Trap_T004  Trap_T005  \\\n",
       "12459          0           0           0          0          0          0   \n",
       "835            0           0           0          0          0          0   \n",
       "7445           0           0           0          0          0          0   \n",
       "2504           0           0           0          0          0          0   \n",
       "6156           0           0           0          0          0          0   \n",
       "\n",
       "       Trap_T006  Trap_T007  Trap_T008  Trap_T009  Trap_T011  Trap_T012  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T013  Trap_T014  Trap_T015  Trap_T016  Trap_T017  Trap_T018  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T019  Trap_T025  Trap_T027  Trap_T028  Trap_T030  Trap_T031  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          1          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T033  Trap_T034  Trap_T035  Trap_T036  Trap_T037  Trap_T039  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          1   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T040  Trap_T043  Trap_T044  Trap_T045  Trap_T046  Trap_T047  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T048  Trap_T049  Trap_T050  Trap_T051  Trap_T054  Trap_T054C  \\\n",
       "12459          0          0          0          0          0           0   \n",
       "835            1          0          0          0          0           0   \n",
       "7445           0          0          0          0          0           0   \n",
       "2504           0          0          0          0          0           0   \n",
       "6156           0          0          0          0          0           0   \n",
       "\n",
       "       Trap_T060  Trap_T061  Trap_T062  Trap_T063  Trap_T065  Trap_T065A  \\\n",
       "12459          0          0          0          0          0           0   \n",
       "835            0          0          0          0          0           0   \n",
       "7445           0          0          0          0          0           0   \n",
       "2504           0          0          0          0          0           0   \n",
       "6156           0          0          0          0          0           0   \n",
       "\n",
       "       Trap_T066  Trap_T067  Trap_T069  Trap_T070  Trap_T071  Trap_T072  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T073  Trap_T074  Trap_T075  Trap_T076  Trap_T077  Trap_T078  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T079  Trap_T080  Trap_T081  Trap_T082  Trap_T083  Trap_T084  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          1          0          0          0          0   \n",
       "\n",
       "       Trap_T085  Trap_T086  Trap_T088  Trap_T089  Trap_T090  Trap_T090A  \\\n",
       "12459          0          0          0          0          0           0   \n",
       "835            0          0          0          0          0           0   \n",
       "7445           0          0          0          0          0           0   \n",
       "2504           0          0          0          0          0           0   \n",
       "6156           0          0          0          0          0           0   \n",
       "\n",
       "       Trap_T090B  Trap_T090C  Trap_T091  Trap_T092  Trap_T094  Trap_T094B  \\\n",
       "12459           0           0          0          0          0           0   \n",
       "835             0           0          0          0          0           0   \n",
       "7445            0           0          0          0          0           0   \n",
       "2504            0           0          0          0          0           0   \n",
       "6156            0           0          0          0          0           0   \n",
       "\n",
       "       Trap_T095  Trap_T096  Trap_T097  Trap_T099  Trap_T100  Trap_T102  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T103  Trap_T107  Trap_T114  Trap_T115  Trap_T128  Trap_T128A  \\\n",
       "12459          0          0          0          0          0           0   \n",
       "835            0          0          0          0          0           0   \n",
       "7445           0          0          0          0          0           0   \n",
       "2504           0          0          0          0          0           0   \n",
       "6156           0          0          0          0          0           0   \n",
       "\n",
       "       Trap_T129  Trap_T135  Trap_T138  Trap_T141  Trap_T142  Trap_T143  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T144  Trap_T145  Trap_T146  Trap_T147  Trap_T148  Trap_T149  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T150  Trap_T151  Trap_T152  Trap_T153  Trap_T154  Trap_T155  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T156  Trap_T157  Trap_T158  Trap_T159  Trap_T160  Trap_T161  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T162  Trap_T200  Trap_T200A  Trap_T200B  Trap_T206  Trap_T209  \\\n",
       "12459          0          0           0           0          0          0   \n",
       "835            0          0           0           0          0          0   \n",
       "7445           0          0           0           0          0          0   \n",
       "2504           0          0           0           0          0          0   \n",
       "6156           0          0           0           0          0          0   \n",
       "\n",
       "       Trap_T212  Trap_T215  Trap_T218  Trap_T218A  Trap_T218B  Trap_T218C  \\\n",
       "12459          0          0          0           0           0           0   \n",
       "835            0          0          0           0           0           0   \n",
       "7445           0          0          0           0           0           0   \n",
       "2504           0          0          0           0           0           0   \n",
       "6156           0          0          0           0           0           0   \n",
       "\n",
       "       Trap_T219  Trap_T220  Trap_T221  Trap_T222  Trap_T223  Trap_T224  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T225  Trap_T226  Trap_T227  Trap_T228  Trap_T229  Trap_T230  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T231  Trap_T232  Trap_T233  Trap_T234  Trap_T235  Trap_T236  \\\n",
       "12459          0          0          0          0          0          0   \n",
       "835            0          0          0          0          0          0   \n",
       "7445           0          0          0          0          0          0   \n",
       "2504           0          0          0          0          0          0   \n",
       "6156           0          0          0          0          0          0   \n",
       "\n",
       "       Trap_T237  Trap_T238  Trap_T900  Trap_T903  \n",
       "12459          1          0          0          0  \n",
       "835            0          0          0          0  \n",
       "7445           0          0          0          0  \n",
       "2504           0          0          0          0  \n",
       "6156           0          0          0          0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Classifiers\n",
    "clf_lr  = LogisticRegression(solver='liblinear', random_state=0)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf  = RandomForestClassifier(random_state=0)\n",
    "clf_svc = SVC(random_state=0)\n",
    "clf_xgc = xgb.XGBClassifier(random_state=0)\n",
    "\n",
    "# Building the model pipelines incl. preprocessing where needed \n",
    "# Note that the random forest and xgboost does not need feature scaling\n",
    "pipe_lr  = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_lr', clf_lr)])\n",
    "\n",
    "pipe_svc = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_svc', clf_svc)])\n",
    "\n",
    "pipe_knn = Pipeline([('std', StandardScaler()),\n",
    "                     ('clf_knn', clf_knn)])\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid_lr  = [{'clf_lr__penalty': ['l1', 'l2'],\n",
    "                   'clf_lr__C': np.logspace(-4, 4, 9)}]\n",
    "\n",
    "param_grid_knn = [{'clf_knn__n_neighbors': list(range(3, 7)),\n",
    "                   'clf_knn__p': [1, 2],\n",
    "                   'clf_knn__leaf_size': [5, 10, 15],\n",
    "                   'clf_knn__weights': ['uniform', 'distance']}]\n",
    "\n",
    "param_grid_rf  = [{'n_estimators': [10, 20, 50, 100, 150, 200],\n",
    "                   'min_samples_leaf': [2, 5, 10],\n",
    "                   'max_features': ['sqrt', 'log2']}]\n",
    "\n",
    "param_grid_svc = [{'clf_svc__kernel': ['rbf'],\n",
    "                   'clf_svc__C': np.logspace(-1, 3, 5),\n",
    "                   'clf_svc__gamma': np.logspace(-4, 0, 4)[:3]}]\n",
    "\n",
    "param_grid_xgc = [{'xgc__eval_metric' : ['auc'],\n",
    "                   'xgc__subsample' : [0.5], \n",
    "                   'xgc__colsample_bytree' : [0.5], \n",
    "                   'xgc__learning_rate' : [0.1],\n",
    "                   'xgc__max_depth' : [3], \n",
    "                   'xgc__reg_alpha' : [0, 1, 1.5],\n",
    "                   'xgc__reg_lambda' : [1, 2, 5],\n",
    "                   'xgc__gamma' : [0.01, 0.1, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize functions for grid search, calling on above functions, and printing model metrics\n",
    "def grid_search(classifier, params):\n",
    "    gs = GridSearchCV(classifier, param_grid=params, cv=3, scoring='roc_auc', verbose=5)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(f'Train AUC Score: {round(gs.best_score_, 4)}')\n",
    "    print(f'Using the following parameters: {gs.best_params_}')\n",
    "    print('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalscore(classifer_best_params):\n",
    "    model = classifer_best_params.fit(X_train, y_train)\n",
    "    score = cross_val_score(classifer_best_params,\n",
    "                            X=X_train,\n",
    "                            y=y_train,\n",
    "                            cv=5,\n",
    "                            n_jobs=1,\n",
    "                            scoring='roc_auc')\n",
    "    print(score)\n",
    "    print(f'AUC Mean Score {100*score.mean():.2f} +/- {100*score.std():.2f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l1 ............................\n",
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l1, score=0.500, total=   0.2s\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l1, score=0.500, total=   0.1s\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l1 ............................\n",
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l1, score=0.500, total=   0.1s\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l2, score=0.798, total=   0.1s\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l2 ............................\n",
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l2, score=0.757, total=   0.1s\n",
      "[CV] clf_lr__C=0.0001, clf_lr__penalty=l2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=0.0001, clf_lr__penalty=l2, score=0.773, total=   0.1s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l1 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l1, score=0.500, total=   0.1s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l1 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l1, score=0.500, total=   0.1s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l1 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l1, score=0.500, total=   0.1s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l2, score=0.800, total=   0.2s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l2, score=0.762, total=   0.1s\n",
      "[CV] clf_lr__C=0.001, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=0.001, clf_lr__penalty=l2, score=0.773, total=   0.2s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l1 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l1, score=0.769, total=   0.2s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l1 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l1, score=0.706, total=   0.2s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l1 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l1, score=0.740, total=   0.1s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l2, score=0.807, total=   0.2s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l2, score=0.771, total=   0.2s\n",
      "[CV] clf_lr__C=0.01, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=0.01, clf_lr__penalty=l2, score=0.776, total=   0.2s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l1, score=0.806, total=   0.7s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l1, score=0.774, total=   0.5s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l1, score=0.776, total=   0.4s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l2, score=0.812, total=   0.4s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l2, score=0.777, total=   0.3s\n",
      "[CV] clf_lr__C=0.1, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=0.1, clf_lr__penalty=l2, score=0.775, total=   0.4s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l1, score=0.813, total=   1.0s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l1, score=0.778, total=   1.1s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l1 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l1, score=0.770, total=   1.6s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l2, score=0.812, total=   0.6s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l2, score=0.777, total=   0.6s\n",
      "[CV] clf_lr__C=1.0, clf_lr__penalty=l2 ...............................\n",
      "[CV] ... clf_lr__C=1.0, clf_lr__penalty=l2, score=0.769, total=   0.5s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l1 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l1, score=0.811, total=   6.3s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l1 ..............................\n",
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l1, score=0.777, total=   9.9s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l1 ..............................\n",
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l1, score=0.767, total=   7.0s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l2, score=0.810, total=   1.0s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l2, score=0.776, total=   0.8s\n",
      "[CV] clf_lr__C=10.0, clf_lr__penalty=l2 ..............................\n",
      "[CV] .. clf_lr__C=10.0, clf_lr__penalty=l2, score=0.768, total=   0.9s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l1, score=0.810, total=  16.4s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l1, score=0.776, total=  13.2s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l1 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l1, score=0.767, total=   9.6s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l2, score=0.809, total=   1.3s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l2, score=0.776, total=   1.2s\n",
      "[CV] clf_lr__C=100.0, clf_lr__penalty=l2 .............................\n",
      "[CV] . clf_lr__C=100.0, clf_lr__penalty=l2, score=0.767, total=   1.1s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l1, score=0.810, total=   4.2s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l1, score=0.776, total=  10.0s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l1 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l1, score=0.767, total=  11.3s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l2 ............................\n",
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l2, score=0.809, total=   1.7s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l2 ............................\n",
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l2, score=0.776, total=   1.3s\n",
      "[CV] clf_lr__C=1000.0, clf_lr__penalty=l2 ............................\n",
      "[CV]  clf_lr__C=1000.0, clf_lr__penalty=l2, score=0.767, total=   1.3s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l1, score=0.809, total=  20.0s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l1, score=0.776, total=  11.8s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l1 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  else:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l1, score=0.767, total=  12.1s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l2 ...........................\n",
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l2, score=0.809, total=   1.7s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l2 ...........................\n",
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l2, score=0.776, total=   1.3s\n",
      "[CV] clf_lr__C=10000.0, clf_lr__penalty=l2 ...........................\n",
      "[CV]  clf_lr__C=10000.0, clf_lr__penalty=l2, score=0.767, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from: \n",
      "Train AUC Score: 0.7881\n",
      "Using the following parameters: {'clf_lr__C': 0.1, 'clf_lr__penalty': 'l2'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search(pipe_lr, param_grid_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_best = LogisticRegression(solver='liblinear', random_state=0, C=0.1, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80779744 0.73483595 0.74259281 0.73614388 0.77209691]\n",
      "AUC Mean Score 75.87 +/- 2.80\n"
     ]
    }
   ],
   "source": [
    "crossvalscore(clf_lr_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.797, total=   6.5s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.769, total=   6.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.801, total=   6.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.806, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   25.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.775, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.809, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.739, total=   8.0s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.703, total=   8.0s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.750, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.738, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.704, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.753, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.816, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.784, total=   7.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.802, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.829, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.792, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.816, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.774, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.723, total=   8.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.766, total=   8.0s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.775, total=   8.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.725, total=   8.2s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.772, total=   8.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.829, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.785, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.800, total=   7.9s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   8.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.797, total=   8.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.784, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.743, total=   8.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.778, total=   8.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.788, total=   8.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.745, total=   8.8s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.786, total=   8.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.826, total=   9.3s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.791, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.799, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.805, total=   8.6s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   8.7s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.789, total=   9.0s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.754, total=   9.0s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.782, total=   9.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.796, total=   9.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.757, total=   9.1s\n",
      "[CV] clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=5, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.792, total=   9.4s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.797, total=   6.4s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.769, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.801, total=   6.0s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.806, total=   6.3s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.775, total=   6.0s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.809, total=   5.9s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.739, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.703, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.750, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.738, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.704, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.753, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.816, total=   8.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.784, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.802, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.829, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.792, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.816, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.774, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.723, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.766, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.775, total=   7.0s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.725, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.772, total=   7.0s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.829, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.785, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.800, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.797, total=   7.9s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.784, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.743, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.778, total=   7.4s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.788, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.745, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.786, total=   7.7s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.826, total=   8.0s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.791, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.799, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.805, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   7.8s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.789, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.754, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.782, total=   7.9s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.796, total=   8.4s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.757, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=10, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.792, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.797, total=   6.4s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.769, total=   6.1s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=uniform, score=0.801, total=   7.0s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.806, total=   7.1s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.775, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=1, clf_knn__weights=distance, score=0.809, total=   6.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.739, total=   6.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.703, total=   6.6s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=uniform, score=0.750, total=   6.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.738, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.704, total=   7.1s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=3, clf_knn__p=2, clf_knn__weights=distance, score=0.753, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.816, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.784, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=uniform, score=0.802, total=   6.7s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.829, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.792, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=1, clf_knn__weights=distance, score=0.816, total=   8.0s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.774, total=   7.0s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.723, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=uniform, score=0.766, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.775, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.725, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=4, clf_knn__p=2, clf_knn__weights=distance, score=0.772, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.829, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.785, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=uniform, score=0.800, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   6.8s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.797, total=   7.1s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.784, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.743, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=uniform, score=0.778, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.788, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.745, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=5, clf_knn__p=2, clf_knn__weights=distance, score=0.786, total=   6.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.826, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.791, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=uniform, score=0.799, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.845, total=   7.9s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.805, total=   8.2s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=1, clf_knn__weights=distance, score=0.819, total=   7.6s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.789, total=   7.3s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.754, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=uniform, score=0.782, total=   7.5s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.796, total=   7.4s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.757, total=   7.2s\n",
      "[CV] clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance \n",
      "[CV]  clf_knn__leaf_size=15, clf_knn__n_neighbors=6, clf_knn__p=2, clf_knn__weights=distance, score=0.792, total=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from: \n",
      "Train AUC Score: 0.823\n",
      "Using the following parameters: {'clf_knn__leaf_size': 5, 'clf_knn__n_neighbors': 6, 'clf_knn__p': 1, 'clf_knn__weights': 'distance'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search(pipe_knn, param_grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn_best = KNeighborsClassifier(n_neighbors=6, leaf_size=5, p=1, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7449818  0.74224581 0.74867872 0.74579859 0.72543528]\n",
      "AUC Mean Score 74.14 +/- 0.83\n"
     ]
    }
   ],
   "source": [
    "crossvalscore(clf_knn_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "clf_lr  = LogisticRegression(solver='liblinear', random_state=0)\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_rf  = RandomForestClassifier(random_state=0)\n",
    "clf_svc = SVC(random_state=0)\n",
    "clf_xgc = xgb.XGBClassifier(random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=10 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=10, score=0.891, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=10 ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=10, score=0.852, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=10 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=10, score=0.849, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=20 ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=20, score=0.903, total=   0.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=20 ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=20, score=0.867, total=   0.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=20 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=20, score=0.866, total=   0.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=50, score=0.907, total=   0.6s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=50, score=0.880, total=   0.6s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=50, score=0.881, total=   0.6s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=100, score=0.909, total=   1.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=100, score=0.885, total=   1.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=100, score=0.885, total=   1.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=150, score=0.909, total=   1.8s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=150, score=0.885, total=   1.8s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=150, score=0.888, total=   1.8s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=200, score=0.910, total=   2.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=200, score=0.884, total=   2.4s\n",
      "[CV] max_features=sqrt, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=2, n_estimators=200, score=0.890, total=   2.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=10, score=0.873, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=10, score=0.852, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=10, score=0.851, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=20, score=0.889, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=20, score=0.850, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=20, score=0.868, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=50, score=0.893, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=50, score=0.858, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=50, score=0.876, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=100, score=0.895, total=   1.0s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=100, score=0.860, total=   1.0s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=100, score=0.875, total=   1.0s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=150, score=0.893, total=   1.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=150, score=0.862, total=   1.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=150, score=0.876, total=   1.6s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=200, score=0.893, total=   2.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=200, score=0.862, total=   2.0s\n",
      "[CV] max_features=sqrt, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=5, n_estimators=200, score=0.876, total=   2.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=10, score=0.860, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=10, score=0.843, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=10, score=0.851, total=   0.1s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=20, score=0.874, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=20, score=0.843, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=20, score=0.859, total=   0.2s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=50, score=0.880, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=50, score=0.847, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=50, score=0.865, total=   0.5s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=100, score=0.882, total=   0.9s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=100, score=0.847, total=   0.9s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=100, score=0.864, total=   0.9s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=150, score=0.881, total=   1.4s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=150, score=0.846, total=   1.4s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=150, score=0.864, total=   1.3s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=200 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=200, score=0.882, total=   1.8s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=200 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=200, score=0.846, total=   1.8s\n",
      "[CV] max_features=sqrt, min_samples_leaf=10, n_estimators=200 ........\n",
      "[CV]  max_features=sqrt, min_samples_leaf=10, n_estimators=200, score=0.863, total=   1.7s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=10 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=10, score=0.887, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=10 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=10, score=0.854, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=10 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=10, score=0.858, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=20, score=0.900, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=20, score=0.868, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=20, score=0.872, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=50, score=0.904, total=   0.5s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=50, score=0.874, total=   0.5s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=50, score=0.887, total=   0.5s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=100, score=0.908, total=   1.0s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=100, score=0.879, total=   1.0s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=100, score=0.891, total=   0.9s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=150, score=0.911, total=   1.4s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=150, score=0.878, total=   1.4s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=150, score=0.891, total=   1.4s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=200, score=0.910, total=   1.9s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=200, score=0.879, total=   1.9s\n",
      "[CV] max_features=log2, min_samples_leaf=2, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=2, n_estimators=200, score=0.892, total=   1.9s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=10, score=0.864, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=10, score=0.824, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=10 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=10, score=0.851, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=20, score=0.875, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=20, score=0.834, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=20 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=20, score=0.857, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=50, score=0.890, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=50, score=0.841, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=50 ..........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=50, score=0.867, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=100, score=0.892, total=   0.8s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=100, score=0.850, total=   0.8s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=100 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=100, score=0.871, total=   0.8s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=150, score=0.893, total=   1.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=150, score=0.851, total=   1.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=150 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=150, score=0.872, total=   1.2s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=200, score=0.892, total=   1.6s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=200, score=0.852, total=   1.6s\n",
      "[CV] max_features=log2, min_samples_leaf=5, n_estimators=200 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=5, n_estimators=200, score=0.874, total=   1.6s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=10, score=0.845, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=10, score=0.818, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=10 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=10, score=0.838, total=   0.1s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=20, score=0.864, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=20, score=0.829, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=20 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=20, score=0.841, total=   0.2s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=50, score=0.873, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=50, score=0.836, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=50 .........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=50, score=0.852, total=   0.4s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=100, score=0.874, total=   0.7s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=100, score=0.840, total=   0.7s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=100 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=100, score=0.855, total=   0.7s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=150, score=0.876, total=   1.0s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=150, score=0.838, total=   1.0s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=150 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=150, score=0.858, total=   1.0s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=200 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=200, score=0.877, total=   1.6s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=200 ........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=200, score=0.837, total=   1.4s\n",
      "[CV] max_features=log2, min_samples_leaf=10, n_estimators=200 ........\n",
      "[CV]  max_features=log2, min_samples_leaf=10, n_estimators=200, score=0.857, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from: \n",
      "Train AUC Score: 0.895\n",
      "Using the following parameters: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 200}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search(clf_rf, param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_best = RandomForestClassifier(max_features='sqrt', min_samples_leaf=2, n_estimators=200, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91821128 0.90743281 0.89757258 0.90559903 0.91742319]\n",
      "AUC Mean Score 90.92 +/- 0.77\n"
     ]
    }
   ],
   "source": [
    "crossvalscore(clf_rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] clf_svc__C=0.1, clf_svc__gamma=0.0001, clf_svc__kernel=rbf ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_svc__C=0.1, clf_svc__gamma=0.0001, clf_svc__kernel=rbf, score=0.611, total=   3.0s\n",
      "[CV] clf_svc__C=0.1, clf_svc__gamma=0.0001, clf_svc__kernel=rbf ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf_svc__C=0.1, clf_svc__gamma=0.0001, clf_svc__kernel=rbf, score=0.632, total=   2.9s\n",
      "[CV] clf_svc__C=0.1, clf_svc__gamma=0.0001, clf_svc__kernel=rbf ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-46b7b44ae36b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_svc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid_svc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-90bf95da4bdb>\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(classifier, params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Train AUC Score: {round(gs.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Using the following parameters: {gs.best_params_}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[1;32m---> 88\u001b[1;33m                                       *args, **kwargs)\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decision_function\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;31m# For multi-output multi-class estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0mof\u001b[0m \u001b[0movo\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \"\"\"\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ovr'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mdec_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mdec_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;31m# In binary case, we need to flip the sign of coef, intercept and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLIBSVM_IMPL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             coef0=self.coef0, gamma=self._gamma)\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search(pipe_svc, param_grid_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc_best = SVC(random_state=0, C=1000, gamma=0.002154, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88832093 0.88864925 0.89896059 0.88713311 0.88666905]\n",
      "AUC Mean Score 88.99 +/- 0.46\n"
     ]
    }
   ],
   "source": [
    "crossvalscore(clf_svc_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:10:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   2.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:10:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   2.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:10:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   2.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:10:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   2.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:10:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   2.8s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:10:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   2.9s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:10:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   2.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:10:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   2.8s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:10:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   2.9s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:11:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:11:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.01, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:11:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   4.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:12:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:12:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.8s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:12:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.1s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:12:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:12:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.0s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:12:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.9s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.9s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.9s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:13:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:13:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:13:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=0.1, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   4.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:13:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:13:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:13:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:14:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=0, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   4.2s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.8s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.8s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:14:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:14:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.7s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:14:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.916, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5 \n",
      "[19:14:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=1, xgc__subsample=0.5, score=0.892, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.916, total=   3.6s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.890, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5 \n",
      "[19:14:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=2, xgc__subsample=0.5, score=0.892, total=   3.4s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:14:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.916, total=   3.3s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:15:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.890, total=   3.5s\n",
      "[CV] xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5 \n",
      "[19:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  xgc__colsample_bytree=0.5, xgc__eval_metric=auc, xgc__gamma=3, xgc__learning_rate=0.1, xgc__max_depth=3, xgc__reg_alpha=1.5, xgc__reg_lambda=5, xgc__subsample=0.5, score=0.892, total=   3.6s\n",
      "[19:15:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { xgc__colsample_bytree, xgc__eval_metric, xgc__gamma, xgc__learning_rate, xgc__max_depth, xgc__reg_alpha, xgc__reg_lambda, xgc__subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC Score: 0.8996\n",
      "Using the following parameters: {'xgc__colsample_bytree': 0.5, 'xgc__eval_metric': 'auc', 'xgc__gamma': 0.01, 'xgc__learning_rate': 0.1, 'xgc__max_depth': 3, 'xgc__reg_alpha': 0, 'xgc__reg_lambda': 1, 'xgc__subsample': 0.5}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search(clf_xgc, param_grid_xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgc_best = xgb.XGBClassifier(random_state = 0,\n",
    "                                 colsample_bytree=0.5,\n",
    "                                 eval_metric='auc',\n",
    "                                 gamma=0.01,\n",
    "                                 learning_rate=0.1,\n",
    "                                 max_depth=3,\n",
    "                                 reg_alpha=0,\n",
    "                                 reg_lambda=1,\n",
    "                                 subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88447186 0.85751236 0.85267166 0.84720635 0.88202517]\n",
      "AUC Mean Score 86.48 +/- 1.54\n"
     ]
    }
   ],
   "source": [
    "crossvalscore(clf_xgc_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR\n",
    "[0.80779744 0.73483595 0.74259281 0.73614388 0.77209691]\n",
    "AUC Mean Score 75.87 +/- 2.80\n",
    "\n",
    "K Nearest Neighbor\n",
    "[0.7449818  0.74224581 0.74867872 0.74579859 0.72543528]\n",
    "AUC Mean Score 74.14 +/- 0.83\n",
    "\n",
    "Random Forest\n",
    "[0.91821128 0.90743281 0.89757258 0.90559903 0.91742319]\n",
    "AUC Mean Score 90.92 +/- 0.77\n",
    "\n",
    "SVM\n",
    "[0.88832093 0.88864925 0.89896059 0.88713311 0.88666905]\n",
    "AUC Mean Score 88.99 +/- 0.46\n",
    "\n",
    "XGBoost\n",
    "[0.88447186 0.85751236 0.85267166 0.84720635 0.88202517]\n",
    "AUC Mean Score 86.48 +/- 1.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithm Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression ROC_AUC Mean Score(std): `75.87 +/- 2.80`\n",
    "- K Nearest Neighbor ROC_AUC Mean Score(std): `74.14 +/- 0.83`\n",
    "- Random Forest ROC_AUC Mean Score(std): `90.92 +/- 0.77`\n",
    "- Support Vector Classification ROC_AUC Mean Score(std): `88.99 +/- 0.46`\n",
    "- XGBoost ROC_AUC Mean Score(std): `86.48 +/- 1.54`\n",
    "\n",
    "Using `GridSearchCV` followed by `cross_val_score` we were able to tune the respective classifier with the optimised hyperparameters and then check if the learning algorithm is capable of yielding high mean score and low variances as we would want the selected learning algorithm to be capable of producing similar performance on unseen data. In this case it will be the test set provided by kaggle. \n",
    "\n",
    "By comparing the above scores, the final learning algorithm that is choosen is Support Vector Classification. Using the best parameters selected `C = 1000`, `gamma = 0.002154`(rounded to 6 decimal places) and `kernel = 'rbf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_algo = SVC(random_state=0, C=1000, gamma=0.002154, kernel='rbf', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_algo.fit(X_train, y_train)\n",
    "train_auc = roc_auc_score(y_true=y_train, y_score=best_algo.predict_proba(X_train)[:,1])\n",
    "test_auc = roc_auc_score(y_true=y_test, y_score=best_algo.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ROC AUC: 96.52\n",
      "Test ROC AUC: 92.33\n"
     ]
    }
   ],
   "source": [
    "print(f'Training ROC AUC: {100*train_auc:.2f}')\n",
    "print(f'Test ROC AUC: {100*test_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both train test split to do a final train and then evaluate against kaggle and check score!\n",
    "# final model for kaggle prediction\n",
    "X_final, y_final = df_train_final.drop(columns='WnvPresent', axis=1), df_train_final['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.002154, probability=True, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_algo.fit(X_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_auc = roc_auc_score(y_true=y_final, y_score=best_algo.predict_proba(X_final)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620726860188209"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_final = df_prediction_final[df_prediction_final['Station'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_preds = best_algo.predict_proba(df_prediction_final)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = pd.read_csv('../assets/processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test = processed_test[processed_test['Station'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = pd.DataFrame({'Id': processed_test.Id, 'WnvPresent': kaggle_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file.to_csv('../assets/kaggle_submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Benefit Analysis of Spray operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost of spraying operations\n",
    "\n",
    "The city of Chicago started <a href = \"https://chicago.cbslocal.com/2017/08/30/spray-mosquitoes-far-south-side-west-nile-prevention/\"> spraying operations </a> for the first time in the first week of September 2017 in areas of the Pullman and South Deering neighborhoods. The operation starts at dusk (around 6.49 pm according to the weather dataset) and lasts till 1 a.m, making it an average of about 5 hours of spraying. The spraying is done by licensed mosquito abatement technicians in trucks dispensing an ultra-low-volume spray. The main chemical used is <a href = \"https://www.cmmcp.org/pesticide-information/pages/zenivex-e4-etofenprox\">Zenivex E4 </a>, which is  4% solution of a chemical known as Etofenprox, a reduced risk synthetic pyrethroid with an extremely low toxicity to mammals. It is sprayed from a truck at 4.5-9.0 ounces per minute, at a vehicle speed of 10-15 mph (16 to 24 kmh). The cost of Zenivex E4 is about USD \\$80 per gallon according to <a href = \"http://www.gfmosquito.com/wp-content/uploads/2013/06/2013-North-Dakota-Bid-Tabulation.pdf\"> tender information in North Dakota </a>.\n",
    "\n",
    "<img src=\"http://www.meepi.org/wnv/graphics/trucksprayjpg.jpg\" alt=\"ULV Sprayer in the City of Chicago\" width=\"400\">\n",
    "\n",
    "Assuming each truck travels at the lowest speed of 16 kmh, a single truck can spray approximately (16 km $\\times$ 0.003 km $\\times$ 5 hours) in a single night, covering 0.24 km<sup>2</sup>. We assume there is no overlap in the spray area. If each truck were to spray an average of 6.75 ounces (0.05 gallon) per minute. Each truck would spray 3 gallons of Zenivex E4 per hour and hence 15 gallons a night. The total cost of Zenivex E4 for a truck for a night would hence be USD 80 per gallon $\\times$ 15 gallons = **USD 1,200** covering **0.24 km<sup>2</sup>**. The cost to spray **1 km<sup>2</sup>** will be approximately **USD 5,000**.\n",
    "\n",
    "If each truck were to travel at the highest speed of 24 kmh, a single truck can spray approximately (24 km $\\times$ 0.003 km $\\times$ 5 hours) in a single night, covering 0.36 km<sup>2</sup>. Assuming the cost for Zenivex E4 per truck for the entire night is the same as above, we would spend **USD 1,200** covering 0.36 km<sup>2</sup> per truck. The cost to spray **1 km<sup>2</sup>** will be approximately **USD 3,333**.\n",
    "\n",
    "Considering the city of Chicago has a total areas of 606.1 km<sup>2</sup>, it would cost between **USD 2.02 - USD 3.03 million** to cover the entire city assuming there are enough trucks and fuel costs and worker salaries are negligible with almost no wastage of chemicals. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of spraying operations\n",
    "\n",
    "There are multiple benefits from a reduced mosquito population as a result of spraying. These include an increased quality of life from fewer people falling sick and dying, increased workplace productivity from fewer people falling ill and going on medical leave, as well as savings in hospital expenses from treating WNV patients. Of these, only the latter two are measurable.\n",
    "\n",
    "About 1 in 5 people infected with WNV develop the highly incapacitative <a href = \"https://www.uptodate.com/contents/west-nile-virus-infection-beyond-the-basics\">West Nile fever </a> with other symptoms such as headache, body aches, joint pains, vomiting, etc. Recovery from West Nile fever takes from a few days to several weeks, and prolonged fatigue is common.\n",
    "\n",
    "About 1 in 150 people infected develop severe neuroinvasive diseases such as encephalitis or meningitis, in which the virus travels through the blood and infects the brain and spinal cord. Recovery is prolonged and less than 40% of patients with the severe diseases recover after one year.\n",
    "\n",
    "Given that the <a href=\"https://datausa.io/profile/geo/chicago-il/\">median household income</a> in Chicago was \\\\$55,295 (as of 2017), one can estimate the amount of losses the city will face from a workforce affected by WNV. \n",
    "\n",
    "In 2017, there were <a href=\"https://chicago.cbslocal.com/2018/08/29/west-nile-virus-death-reported-in-illinois/\"> 90 WNV cases, including 8 deaths </a>. This means that approximately 18 people developed West Nile fever. Assuming all were working adults and each took two weeks off work to recover, this would have resulted in a total income loss of \\\\$38,281 in total. On average, each WNV patient spends approximately \\\\$25,000 in the hospital. Therefore the total monetary loss caused by WNV in 2017 is approximately **\\\\$488,281**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and recomendations of Cost-Benefit Analysis\n",
    "\n",
    "---\n",
    "\n",
    "Examination of the the total costs of spraying the whole of Chicago compared against the benefits show that the costs far outweigh the benefits in monetary terms. At best, accounting for inflation or even a pessimistic outcome of having 50% more WNV infections, the total monetary benefit to Chicago as a society may only be 16%-25% of the total cost of spraying.\n",
    "\n",
    "However, our model does not take into account any non-monetary benefits to reducing the mosquito population. These include the emotional costs from loss of life, the reduction in the need for enhanced testing for suspected WNV cases and public confidence in the government.\n",
    "\n",
    "From previous geospatial analysis of spray data, there is a distinct lack of evidence to support the claim that mosquito spraying had any effect on the reduction of WNV-infected mosquitos. Furthermore, the spray data pointed towards highly fragmented and haphazardous spraying operations that did not seem to be driven by the evidence if the presence and severity of WNV mosquito infestations. Traps such as the T900 trap at O'Hare International airport which proved to capture the most WNV-infected mosquitos by far were not sprayed. \n",
    "\n",
    "Given the high costs required to conduct spraying operations, we hence recommend the following action points:\n",
    "\n",
    "1. Re-examine the effectiveness of spraying Zenivex E4 as a means to control the mosquito population. Evidence points towards the ineffectiveness of the chemical and it is likely that other kinds of non-toxic mosquito sprays should be explored.\n",
    "\n",
    "2. Re-direct mosquito spraying operations in a more organised and evidence-driven manner whereby severe hotspots such as O'Hare International Airport are sprayed first at the beginning of summer in order to prevent large populations of mosquitos forming. In addition, spraying operations should be accurately logged and routes planned to make sure mosquito breeding sites are properly covered.\n",
    "\n",
    "3. Examine new ways of controlling the mosquito population that may arguably cost less than spraying the whole of Chicago. Innovative ways of doing so may include 'anti-mosquit' campaigns done in places such as Singapore or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
